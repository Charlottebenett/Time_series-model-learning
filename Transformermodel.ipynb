{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/OD5zrYKxYu5DdTGO+4Wh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charlottebenett/aimarketing_app/blob/main/Transformermodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries classification with a Transformer model"
      ],
      "metadata": {
        "id": "UZZr4PcAR9jC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PPgZD7SRNxT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "LqOwTK63SQfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "RGvfhe9aVJ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=150,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ShQp_aCVZ2J",
        "outputId": "7a1e4b14-901e-4c8f-f0c3-199bb88d64f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 500, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 500, 1)               7169      ['input_1[0][0]',             \n",
            " iHeadAttention)                                                     'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 500, 1)               0         ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 500, 1)               2         ['dropout[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 500, 1)               0         ['layer_normalization[0][0]', \n",
            " Lambda)                                                             'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 500, 4)               8         ['tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 500, 4)               0         ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 500, 1)               5         ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 500, 1)               2         ['conv1d_1[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 500, 1)               0         ['layer_normalization_1[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_1[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 500, 1)               2         ['dropout_2[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 500, 1)               0         ['layer_normalization_2[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_1[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 500, 4)               0         ['conv1d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 500, 1)               5         ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 500, 1)               2         ['conv1d_3[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 500, 1)               0         ['layer_normalization_3[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_2[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_3[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 500, 1)               2         ['dropout_4[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TF  (None, 500, 1)               0         ['layer_normalization_4[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_3[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 500, 4)               0         ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 500, 1)               5         ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 500, 1)               2         ['conv1d_5[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TF  (None, 500, 1)               0         ['layer_normalization_5[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_4[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_5[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 500, 1)               2         ['dropout_6[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TF  (None, 500, 1)               0         ['layer_normalization_6[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_5[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 500, 4)               0         ['conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 500, 1)               5         ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 500, 1)               2         ['conv1d_7[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TF  (None, 500, 1)               0         ['layer_normalization_7[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_6[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 500)                  0         ['tf.__operators__.add_7[0][0]\n",
            " GlobalAveragePooling1D)                                            ']                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  64128     ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    258       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93130 (363.79 KB)\n",
            "Trainable params: 93130 (363.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "45/45 [==============================] - 43s 483ms/step - loss: 1.0207 - sparse_categorical_accuracy: 0.5236 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.5673\n",
            "Epoch 2/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.8729 - sparse_categorical_accuracy: 0.5628 - val_loss: 0.6600 - val_sparse_categorical_accuracy: 0.6297\n",
            "Epoch 3/150\n",
            "45/45 [==============================] - 21s 464ms/step - loss: 0.7956 - sparse_categorical_accuracy: 0.5983 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.6630\n",
            "Epoch 4/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.7683 - sparse_categorical_accuracy: 0.6090 - val_loss: 0.5889 - val_sparse_categorical_accuracy: 0.6782\n",
            "Epoch 5/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.7133 - sparse_categorical_accuracy: 0.6330 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.7129\n",
            "Epoch 6/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.5524 - val_sparse_categorical_accuracy: 0.7157\n",
            "Epoch 7/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6733 - val_loss: 0.5413 - val_sparse_categorical_accuracy: 0.7309\n",
            "Epoch 8/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6705 - val_loss: 0.5323 - val_sparse_categorical_accuracy: 0.7365\n",
            "Epoch 9/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.6212 - sparse_categorical_accuracy: 0.6944 - val_loss: 0.5220 - val_sparse_categorical_accuracy: 0.7517\n",
            "Epoch 10/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.6020 - sparse_categorical_accuracy: 0.6955 - val_loss: 0.5163 - val_sparse_categorical_accuracy: 0.7601\n",
            "Epoch 11/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.5981 - sparse_categorical_accuracy: 0.7045 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.7684\n",
            "Epoch 12/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.7139 - val_loss: 0.5007 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 13/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7149 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.7781\n",
            "Epoch 14/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.4904 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 15/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.4851 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 16/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.5332 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.7753\n",
            "Epoch 17/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.4891 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.7878\n",
            "Epoch 18/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.5058 - sparse_categorical_accuracy: 0.7587 - val_loss: 0.4665 - val_sparse_categorical_accuracy: 0.7906\n",
            "Epoch 19/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.4891 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.7933\n",
            "Epoch 20/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4939 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.4574 - val_sparse_categorical_accuracy: 0.7906\n",
            "Epoch 21/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.4744 - sparse_categorical_accuracy: 0.7684 - val_loss: 0.4539 - val_sparse_categorical_accuracy: 0.7933\n",
            "Epoch 22/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 23/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.7975\n",
            "Epoch 24/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.7878 - val_loss: 0.4433 - val_sparse_categorical_accuracy: 0.7933\n",
            "Epoch 25/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8072\n",
            "Epoch 26/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4465 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 27/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8141\n",
            "Epoch 28/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4285 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 29/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.4144 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 30/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.4167 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 31/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3968 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8197\n",
            "Epoch 32/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.4200 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 33/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.3968 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.4146 - val_sparse_categorical_accuracy: 0.8239\n",
            "Epoch 34/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3837 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.4111 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 35/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.4059 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 36/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.4023 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 37/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3662 - sparse_categorical_accuracy: 0.8413 - val_loss: 0.4003 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 38/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3599 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 39/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3653 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 40/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3525 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.3933 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 41/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.3549 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.3912 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 42/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.3456 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.3871 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 43/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3460 - sparse_categorical_accuracy: 0.8500 - val_loss: 0.3842 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 44/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3326 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.3842 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 45/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8660 - val_loss: 0.3804 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 46/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3299 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.3775 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 47/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3285 - sparse_categorical_accuracy: 0.8646 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 48/150\n",
            "45/45 [==============================] - 22s 486ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8747 - val_loss: 0.3738 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 49/150\n",
            "45/45 [==============================] - 21s 469ms/step - loss: 0.3306 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.3727 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 50/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.3142 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3701 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 51/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3223 - sparse_categorical_accuracy: 0.8628 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 52/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.3657 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 53/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.3095 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.3688 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 54/150\n",
            "45/45 [==============================] - 21s 466ms/step - loss: 0.3089 - sparse_categorical_accuracy: 0.8694 - val_loss: 0.3667 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 55/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3034 - sparse_categorical_accuracy: 0.8781 - val_loss: 0.3639 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 56/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.3021 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.3603 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 57/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2903 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 58/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 59/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2896 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.3566 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 60/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2796 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.3540 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 61/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.3570 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 62/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.8927 - val_loss: 0.3523 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 63/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2691 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.3515 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 64/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.3508 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 65/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.3463 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 66/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 67/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2544 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 68/150\n",
            "45/45 [==============================] - 22s 483ms/step - loss: 0.2672 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.3462 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 69/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2663 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.3434 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 70/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2555 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.3427 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 71/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 72/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2487 - sparse_categorical_accuracy: 0.9090 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 73/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.2373 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.3402 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 74/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2538 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.3409 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 75/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2473 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.3373 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 76/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9090 - val_loss: 0.3369 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 77/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3366 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 78/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 79/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 80/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3351 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 81/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2393 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.3330 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 82/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2348 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3345 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 83/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2205 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.3332 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 84/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 85/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2275 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.3267 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 86/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2216 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 87/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2173 - sparse_categorical_accuracy: 0.9264 - val_loss: 0.3261 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 88/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3244 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 89/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3244 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 90/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2107 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 91/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2125 - sparse_categorical_accuracy: 0.9222 - val_loss: 0.3270 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 92/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2153 - sparse_categorical_accuracy: 0.9201 - val_loss: 0.3254 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 93/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2085 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 94/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2054 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.3221 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 95/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2026 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 96/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.3189 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 97/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3195 - val_sparse_categorical_accuracy: 0.8724\n",
            "Epoch 98/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.2039 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.3181 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 99/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.2002 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.3164 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 100/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1972 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 101/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1952 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.3152 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 102/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1892 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 103/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3176 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 104/150\n",
            "45/45 [==============================] - 22s 483ms/step - loss: 0.1943 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.3174 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 105/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3184 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 106/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 107/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.8724\n",
            "Epoch 108/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 109/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1861 - sparse_categorical_accuracy: 0.9378 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 110/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3107 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 111/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3072 - val_sparse_categorical_accuracy: 0.8752\n",
            "Epoch 112/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1744 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.3102 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 113/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3093 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 114/150\n",
            "45/45 [==============================] - 22s 483ms/step - loss: 0.1681 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 115/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1761 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.3104 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 116/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9424 - val_loss: 0.3098 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 117/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 118/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3104 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 119/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.3105 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 120/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3074 - val_sparse_categorical_accuracy: 0.8724\n",
            "Epoch 121/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.1612 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8752\n",
            "Epoch 122/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.3087 - val_sparse_categorical_accuracy: 0.8710\n",
            "Epoch 123/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.8738\n",
            "Epoch 124/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1608 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.3022 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 125/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3041 - val_sparse_categorical_accuracy: 0.8752\n",
            "Epoch 126/150\n",
            "45/45 [==============================] - 21s 466ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 127/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 128/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.3050 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 129/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3015 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 130/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1581 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3022 - val_sparse_categorical_accuracy: 0.8863\n",
            "Epoch 131/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.3018 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 132/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1534 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3010 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 133/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3044 - val_sparse_categorical_accuracy: 0.8738\n",
            "Epoch 134/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.8821\n",
            "Epoch 135/150\n",
            "45/45 [==============================] - 22s 483ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.8724\n",
            "Epoch 136/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1479 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3025 - val_sparse_categorical_accuracy: 0.8793\n",
            "Epoch 137/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3021 - val_sparse_categorical_accuracy: 0.8738\n",
            "Epoch 138/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8821\n",
            "Epoch 139/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2998 - val_sparse_categorical_accuracy: 0.8738\n",
            "Epoch 140/150\n",
            "45/45 [==============================] - 21s 468ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 141/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.3019 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 142/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3026 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 143/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.8724\n",
            "Epoch 144/150\n",
            "45/45 [==============================] - 21s 466ms/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.3026 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 145/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3024 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 146/150\n",
            "45/45 [==============================] - 21s 467ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.3030 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 147/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.8835\n",
            "Epoch 148/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.3002 - val_sparse_categorical_accuracy: 0.8766\n",
            "Epoch 149/150\n",
            "45/45 [==============================] - 22s 484ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.3019 - val_sparse_categorical_accuracy: 0.8849\n",
            "Epoch 150/150\n",
            "45/45 [==============================] - 22s 485ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.8807\n",
            "42/42 [==============================] - 3s 80ms/step - loss: 0.3243 - sparse_categorical_accuracy: 0.8667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3242861330509186, 0.8666666746139526]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}